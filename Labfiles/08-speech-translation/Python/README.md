# ğŸŒ Azure AI Speech Translation - Real-Time Language Translator

## ğŸš€ Project Overview

This project demonstrates **Azure AI Speech Services** for **real-time speech translation** with **text-to-speech synthesis**. The application translates English speech into multiple languages and speaks the translation using native neural voices, including **Egyptian Arabic**! ğŸ‡ªğŸ‡¬

### ğŸ¯ What This Project Does

1. **ğŸ¤ Speech Recognition**: Converts English audio to text
2. **ğŸŒ Language Translation**: Translates English text to target languages
3. **ğŸ”Š Speech Synthesis**: Converts translated text back to speech with native voices
4. **ğŸµ Interactive Interface**: User-friendly language selection menu

---

## ğŸ“‹ Prerequisites

### ğŸ”‘ **Azure Resources Required**
- **Azure AI Speech Service** (Cognitive Services)
- Valid **Speech API Key** and **Region**

### ğŸ› ï¸ **Development Environment**
- Python 3.7+ 
- pip package manager
- Audio file: `station.wav` (provided in project)

---

## âš™ï¸ Setup Instructions

### 1. **Environment Configuration** ğŸ“

Create a `.env` file in the `translator/` directory:

```bash
SPEECH_KEY=your_speech_service_key_here
SPEECH_REGION=your_azure_region_here
```

**Azure Portal Steps:**
1. Create **Azure AI Speech Service** resource
2. Go to **Keys and Endpoint** section
3. Copy **Key 1** â†’ `SPEECH_KEY`
4. Copy **Location/Region** â†’ `SPEECH_REGION`

### 2. **Install Dependencies** ğŸ“¦

```bash
pip install azure-cognitiveservices-speech python-dotenv playsound
```

### 3. **Project Structure** ğŸ“

```
08-speech-translation/Python/
â”œâ”€â”€ translator/
â”‚   â”œâ”€â”€ translator.py      # ğŸ¯ Main translation application
â”‚   â”œâ”€â”€ station.wav        # ğŸµ Sample English audio file
â”‚   â””â”€â”€ .env              # ğŸ” Azure credentials
â””â”€â”€ README.md             # ğŸ“– This documentation
```

---

## ğŸ® How to Run

```bash
cd translator/
python translator.py
```

### **Interactive Menu** ğŸ¯
```
Enter a target language
 fr = French
 es = Spanish  
 hi = Hindi
 ar = Arabic (Egyptian) ğŸ‡ªğŸ‡¬
 save = Save translation audio files  # ğŸ†• TESTING FEATURE
 Enter anything else to stop
```

### **ğŸµ Save Feature for Testing**
Type `save` to generate audio files for all languages at once:
- Creates a `translations/` directory
- Saves 4 audio files: French, Spanish, Hindi, and Egyptian Arabic
- Perfect for testing voice quality and translation accuracy

**Generated Files:**
```
translations/
â”œâ”€â”€ translation_french.wav           # ğŸ‡«ğŸ‡· French (Henri Neural)
â”œâ”€â”€ translation_spanish.wav          # ğŸ‡ªğŸ‡¸ Spanish (Elvira Neural)
â”œâ”€â”€ translation_hindi.wav            # ğŸ‡®ğŸ‡³ Hindi (Madhur Neural)
â””â”€â”€ translation_arabic_egyptian.wav  # ğŸ‡ªğŸ‡¬ Egyptian Arabic (Salma Neural)
```

---

## ğŸ—£ï¸ Supported Languages & Voices

| Language | Code | Neural Voice | Region/Accent |
|----------|------|--------------|---------------|
| ğŸ‡«ğŸ‡· **French** | `fr` | `fr-FR-HenriNeural` | France |
| ğŸ‡ªğŸ‡¸ **Spanish** | `es` | `es-ES-ElviraNeural` | Spain |
| ğŸ‡®ğŸ‡³ **Hindi** | `hi` | `hi-IN-MadhurNeural` | India |
| ğŸ‡ªğŸ‡¬ **Arabic** | `ar` | `ar-EG-SalmaNeural` | **Egypt** |

### ğŸŒŸ **Special Feature: Egyptian Arabic**
The project uses **`ar-EG-SalmaNeural`** - a high-quality neural voice specifically trained for **Egyptian Arabic dialect**, providing authentic pronunciation and intonation! ğŸ­

---

## ğŸ’» Code Explanation

### ğŸ”§ **Main Function Architecture**

```python
def main():
    # ğŸ”‘ Load Azure credentials from .env file
    load_dotenv()
    ai_key = os.getenv('SPEECH_KEY')
    ai_region = os.getenv('SPEECH_REGION')
    
    # ğŸŒ Configure translation service
    translation_config = speech_sdk.translation.SpeechTranslationConfig(ai_key, ai_region)
    translation_config.speech_recognition_language = 'en-US'  # ğŸ¤ Source language
    translation_config.add_target_language('fr')  # ğŸ‡«ğŸ‡· French
    translation_config.add_target_language('es')  # ğŸ‡ªğŸ‡¸ Spanish  
    translation_config.add_target_language('hi')  # ğŸ‡®ğŸ‡³ Hindi
    translation_config.add_target_language('ar')  # ğŸ‡ªğŸ‡¬ Arabic (Egyptian)
```

### ğŸ¯ **Translation Process Flow**

#### **Step 1: Audio Input** ğŸµ
```python
audioFile = 'station.wav'
audio_config = speech_sdk.AudioConfig(filename=audioFile)
translator = speech_sdk.translation.TranslationRecognizer(translation_config, audio_config)
```
- Loads pre-recorded English audio file
- Creates audio configuration for speech recognition

#### **Step 2: Speech Recognition** ğŸ‘‚
```python
result = translator.recognize_once_async().get()
print('Translating "{}"'.format(result.text))  # ğŸ“ Display recognized text
```
- Converts English speech to text
- Shows the recognized English text

#### **Step 3: Language Translation** ğŸŒ
```python
translation = result.translations[targetLanguage]
print(translation)  # ğŸ“‹ Display translated text
```
- Translates English text to selected target language
- Displays the translated text

#### **Step 4: Speech Synthesis** ğŸ”Š
```python
voices = {
    "fr": "fr-FR-HenriNeural",
    "es": "es-ES-ElviraNeural", 
    "hi": "hi-IN-MadhurNeural",
    "ar": "ar-EG-SalmaNeural"  # ğŸ‡ªğŸ‡¬ Egyptian Arabic voice!
}
speech_config.speech_synthesis_voice_name = voices.get(targetLanguage)
speech_synthesizer = speech_sdk.SpeechSynthesizer(speech_config)
speak = speech_synthesizer.speak_text_async(translation).get()
```
- Maps each language to its neural voice
- **Egyptian Arabic** uses `ar-EG-SalmaNeural` for authentic pronunciation
- Converts translated text to natural-sounding speech

---

## ğŸµ Audio Features

### ğŸ§ **PlaysSound Compatibility**
```python
# playsound(audioFile)  # Commented out due to GitHub Codespaces compatibility
```
- **Issue**: PlaysSound may fail in certain environments
- **Solution**: Audio processing continues without playback preview
- **Alternative**: Use local development environment for full audio experience

### ğŸ¤ **Microphone vs File Input**
The code supports both input methods:

**File Input** (Current):
```python
audioFile = 'station.wav'
audio_config = speech_sdk.AudioConfig(filename=audioFile)
```

**Microphone Input** (Available):
```python
# Uncomment for live microphone input:
# audio_config = speech_sdk.AudioConfig(use_default_microphone=True)
```

---

## ğŸŒŸ Key Features Explained

### ğŸ¯ **Multi-Language Support**
- **4 Target Languages**: French, Spanish, Hindi, and Egyptian Arabic
- **Native Voices**: Each language uses region-specific neural voices
- **Real-time Processing**: Instant translation and synthesis

### ğŸ‡ªğŸ‡¬ **Egyptian Arabic Integration**
- **Voice**: `ar-EG-SalmaNeural` - Female Egyptian voice
- **Dialect**: Authentic Egyptian Arabic pronunciation
- **Quality**: High-fidelity neural voice technology

### ğŸ”„ **Interactive Loop**
- **Continuous Operation**: Translate multiple times in one session
- **Language Switching**: Easy switching between target languages
- **Clean Exit**: Type anything other than language codes to stop

---

## ğŸš¨ Troubleshooting

### **Common Issues** ğŸ”§

#### **1. Authentication Errors**
```
Error: Invalid subscription key or service region
```
**Solution**: 
- Verify `SPEECH_KEY` and `SPEECH_REGION` in `.env` file
- Ensure Azure Speech Service is active

#### **2. Audio File Missing**
```
Error: Could not find station.wav
```
**Solution**:
- Ensure `station.wav` exists in the same directory as `translator.py`
- Use absolute path if needed: `audioFile = '/full/path/to/station.wav'`

#### **3. PlaysSound Errors**
```
Error: No module named 'gi'
```
**Solution**:
- This is expected in GitHub Codespaces
- Audio processing continues normally
- For local development, install required system libraries

### **Performance Tips** âš¡
- Use **Standard_S0** tier for production workloads
- Consider **Free tier** limitations for development
- **Network latency** affects real-time translation speed

---

## ğŸ“ Learning Objectives

After completing this project, you'll understand:

- ğŸ¤ **Speech Recognition**: Converting audio to text
- ğŸŒ **Language Translation**: Multi-language text translation  
- ğŸ”Š **Speech Synthesis**: Text-to-speech with neural voices
- ğŸ‡ªğŸ‡¬ **Regional Voices**: Using dialect-specific voices (Egyptian Arabic)
- ğŸ”„ **Real-time Processing**: Chaining speech services together
- ğŸ› ï¸ **Azure Integration**: Configuring and using Azure AI Speech Services

---

## ğŸŒ Supported Azure Regions

Ensure your **Azure Speech Service** is deployed in a supported region:
- **US**: East US, West US 2, Central US
- **Europe**: West Europe, North Europe
- **Asia**: East Asia, Southeast Asia
- **Middle East**: UAE North *(recommended for Arabic)*

---

## ğŸ”— Additional Resources

- [Azure AI Speech Documentation](https://docs.microsoft.com/azure/cognitive-services/speech-service/)
- [Neural Voice Gallery](https://speech.microsoft.com/portal/voicegallery)
- [Language Support Matrix](https://docs.microsoft.com/azure/cognitive-services/speech-service/language-support)
- [Egyptian Arabic Voice Samples](https://speech.microsoft.com/portal/voicegallery)

---

## ğŸ’¡ Next Steps

1. **ğŸ¤ Try Microphone Input**: Uncomment microphone configuration for live speech
2. **ğŸŒ Add More Languages**: Extend the voices dictionary with additional languages
3. **ğŸ“± Build UI Interface**: Create a graphical interface for the translator
4. **ğŸµ Custom Audio**: Use your own audio files for testing
5. **ğŸ”Š Voice Customization**: Experiment with SSML for advanced speech control

---

**ğŸ‰ Happy Translating! Enjoy exploring multi-language speech translation with authentic Egyptian Arabic voices! ğŸ‡ªğŸ‡¬**
